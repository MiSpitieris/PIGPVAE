{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8a1f7e-7773-4d87-a2df-33fe5c97054c",
   "metadata": {},
   "source": [
    "# VAE with Newton's law decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a96416-57ba-4921-96af-34c2776a8c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader,random_split, Subset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from Models.PIVAE import PIVAE\n",
    "from physics import NewtonsLaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcf0f5c-f8e7-4913-9a87-8080a6e95bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d603cec-f2b2-401f-8263-3b34b824cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/46/30710m094qv2_dhfs08nzzd00000gn/T/ipykernel_23587/3618831305.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_c = df_c.groupby('Scheduler Step').apply(select_points).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Import RICO data \n",
    "file_path = '../Data/RICO4_Dataset_processed.hdf'\n",
    "df = pd.read_hdf(file_path)\n",
    "#  define surrounding temperature\n",
    "df.loc[:, 'sur_temp'] = (df['RTD417'] + df['B.ASTRHT2.T'])/2\n",
    "df_c = df.copy()\n",
    "df_c = df[df['temp_change_class'] == 'c']\n",
    "def select_points(group):\n",
    "    return group.iloc[::10]  # Select every 10th row\n",
    "df_c = df_c.groupby('Scheduler Step').apply(select_points).reset_index(drop=True)\n",
    "df_c = df_c.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2edad438-9425-4d93-8eb5-88cb82aa96a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 21\n",
      "Number of batches in val_loader: 7\n"
     ]
    }
   ],
   "source": [
    "class RICO4Dataset(Dataset):\n",
    "    def __init__(self, df, select_var):\n",
    "        self.df = df\n",
    "        self.select_var = select_var\n",
    "        self.unique_batches = df['interval'].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_batches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.unique_batches[idx]\n",
    "        temp = self.df[self.df['interval'] == batch][self.select_var]\n",
    "        \n",
    "        # Normalize and convert to tensors\n",
    "        ti = torch.tensor(temp['time_within_interval'].to_numpy() / 240, dtype=torch.float32)\n",
    "        Ts = torch.tensor(temp['sur_temp'].to_numpy(), dtype=torch.float32)\n",
    "        heat_obs = torch.tensor(temp['B.RTD1'].to_numpy(), dtype=torch.float32)\n",
    "        \n",
    "        # Stack the tensors to create the input batch\n",
    "        x_batch = torch.stack((heat_obs, Ts, ti), dim=1)\n",
    "        \n",
    "        return x_batch\n",
    "# Initialize the dataset and train_loader\n",
    "select_var = ['time_within_interval', 'sur_temp', 'B.RTD1']\n",
    "dataset = RICO4Dataset(df_c,select_var)\n",
    "# Split the dataset into above_20 and below_20\n",
    "above_20_data = []\n",
    "below_20_data = []\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    x_batch = dataset[idx]\n",
    "    starting_value = x_batch[0, 0].item()  # Get the starting value of B.RTD1\n",
    "    if starting_value > 20:\n",
    "        above_20_data.append(x_batch)\n",
    "    else:\n",
    "        below_20_data.append(x_batch)\n",
    "\n",
    "# Define custom datasets for above_20 and below_20\n",
    "class SubsetDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create DataLoader instances\n",
    "below_20_dataset = SubsetDataset(below_20_data)\n",
    "above_20_dataset = SubsetDataset(above_20_data)\n",
    "\n",
    "train_loader = DataLoader(above_20_dataset, batch_size=1, shuffle=True)  # Adjust batch_size as needed\n",
    "val_loader = DataLoader(below_20_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Check DataLoader sizes\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in val_loader: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b3ac64-2118-404b-a4b5-2c7c16453e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Epoch 200/1000 | Loss=1.6626, KL=0.1717, MSE=1.4909\n",
      "Progress: Epoch 400/1000 | Loss=1.7505, KL=0.2124, MSE=1.5380\n",
      "Progress: Epoch 600/1000 | Loss=1.1644, KL=0.2098, MSE=0.9546\n",
      "Progress: Epoch 800/1000 | Loss=1.4822, KL=0.2083, MSE=1.2739\n",
      "Progress: Epoch 1000/1000 | Loss=1.4612, KL=0.2207, MSE=1.2405\n"
     ]
    }
   ],
   "source": [
    "set_seed_(123)\n",
    "model = PIVAE(hidden_layers=[10,10], \n",
    "                 activation=nn.Tanh(),\n",
    "                 mu_prior=torch.tensor(0),\n",
    "                 var_prior=torch.tensor(2.0))\n",
    "# Initialize model parameters and optimizer\n",
    "pars = model.parameters()\n",
    "opt = torch.optim.Adam(pars, lr=0.0001)\n",
    "\n",
    "# Lists to store loss values\n",
    "l_loss, KL, mse = [], [], []\n",
    "\n",
    "# Set beta value and number of epochs\n",
    "beta_phy = 1\n",
    "num_epochs = 1000\n",
    "l_loss, KL, mse = model.fit(train_loader, opt, beta_phy, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e12217-2392-4cd5-ae58-0d4d3898683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'pre_trained_models/PIVAE_cooling.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RICO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
